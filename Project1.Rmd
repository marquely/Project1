---
title: "Project1"
author: Lindsey Marquez
output: word_document
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE)

#change the input file to TCGA_breast_cancer_ERpositive_vs_ERnegative_PAM50.tsv

file <- "TCGA_breast_cancer_ERpositive_vs_ERnegative_PAM50.tsv"
first10 <- c('NAT1','BIRC5','BAG1','BCL2','BLVRA','CCNB1','CCNE1','CDC6','CDC20','CDH3')
```

## Assignment

**1.** For the assignment use the second dataset called TCGA_breast_cancer_ERpositive_vs_ERnegative_PAM50.tsv that shows ER assignment for each sample (Positive vs. Negative).
 
**2.** Compute 5-fold and 10-fold cross-validation estimates of prediction accuracies of ER using all genes by utilizing logistic regression and compare with NNC (2x2 table).

**3.** Modify the the R markdown document template to report your computation and results in a table format.

**4.** Comment on the quality of results

**5.** In the second part of the assignment use Project1fs.R to process a large data set by first removing all genes with sd < 1 and subsequently use Feature selection to pick top 50 genes vs top 100 genes for cross-validation based on the t-test statistic.

**6.** For extra credit â€“ please replace centroid based classifier with one utilizing logistic or lasso regression similarly to the first part of the assignment and report on any difficulties.

## Reading data

Please add R code that reads data here - 
reading file: `r file`

```{r reading_data, echo=FALSE}
system.time({
# important -- this makes sure our runs are consistent and reproducible
set.seed(0)

header <- scan(file, nlines = 1, sep="\t", what = character())
data <- read.table(file, skip = 2, header = FALSE, sep = "\t", quote = "", check.names=FALSE)

header[1] <- "gene_id"
names(data) <- header

header2 <- scan(file, skip = 1, nlines = 1, sep="\t", what = character())
})
```

## Computation

Please add R code that computes the results

```{r computation, echo=FALSE}
Positive <- data[, header2 == "Positive", drop = FALSE]
Negative <- data[, header2 == "Negative", drop = FALSE]

cross_validation <- function(nfold, alg = "centroid")
  { 
  
  # split each cancer type samples into nfold groups
  ERpositive_groups <- split( sample(colnames(Positive)), cut(seq_along(colnames(Positive)), nfold, labels = FALSE) )
  ERnegative_groups <- split( sample(colnames(Negative)), cut(seq_along(colnames(Negative)), nfold, labels = FALSE) )
  
  # create a numeric vector of length "nfold"
  result <- numeric(nfold)
  
  # iterate from 1 to nfold groups
  for (test_group in 1:nfold) {
    
  # return all samples in the chosen test group 
  test_ER_pos <- Positive[, colnames(Positive) %in% unlist(ERpositive_groups[test_group]), drop = FALSE]
  test_ER_neg <- Negative[, colnames(Negative) %in% unlist(ERnegative_groups[test_group]), drop = FALSE]
  
  
  # return all samples not in the chosen test group 
  trainingERpos <- Positive[, !(colnames(Positive) %in% unlist(ERpositive_groups[test_group])), drop = FALSE]
  trainingERneg <- Negative[, !(colnames(Negative) %in% unlist(ERnegative_groups[test_group])), drop = FALSE] 
  
  # centroid function
  if (alg == "centroid") { 
    
    #take row means to calculate centroids
    centroidERpos <- rowMeans(trainingERpos) 
    centroidERneg <- rowMeans(trainingERneg) 
    
    #ensure vector is a matrix
    test_ER_pos <- as.matrix(test_ER_pos) 
    test_ER_neg <- as.matrix(test_ER_neg) 
    
    # calculate misclassified centroid predictions 
    misclassifiedERpos <- sum(apply(test_ER_pos, 2, function(x) sum(abs(x - centroidERpos)) > sum(abs(x - centroidERneg))))
    misclassifiedERneg <- sum(apply(test_ER_neg, 2, function(x) sum(abs(x - centroidERpos)) < sum(abs(x - centroidERneg)))) 
  }
  
  # general linear model function
  if (alg == "GLM") { 
    
  # Build training data frame 
  trainingER <- rbind( cbind(data.frame(t(trainingERpos)), cancer = 1), 
              cbind(data.frame(t(trainingERneg)), cancer = 0) )
  
  # build test data set 
  test_ER <- rbind( data.frame(t(test_ER_pos)), 
              data.frame(t(test_ER_neg)))
  
  # provide true labels 
  truth <- c(rep(1, ncol(test_ER_pos)), rep(0, ncol(test_ER_neg)))
  
  # create logistic regression model
  model <- glm(cancer ~ ., data = trainingER, family = binomial)
  
  # prediction model using regression
  p <- predict(model, newdata = test_ER, type = "response")
  preds <- ifelse(p < 0.5, 0, 1)
  
  # calculate false positive and false negative predictions
  misclassifiedERpos <- sum(preds[truth == 1] == 0)
  misclassifiedERneg <- sum(preds[truth == 0] == 1) } 
  
  # calculate fold-level error rate
  result[test_group] <- (misclassifiedERpos + misclassifiedERneg) / (ncol(test_ER_pos) + ncol(test_ER_neg))
  }
  return(list(mean = mean(result), sd = sd(result)))
}
system.time({
  
ER_Positive <- data[,header2=='Positive']
ER_Negative <- data[,header2=='Negative']

# nfold=5
kNNC_5_all <- cross_validation(nfold=5)
GLM_5_all <- cross_validation(nfold=5, alg="GLM")

# nfold=10
kNNC_10_all <- cross_validation(nfold=10)
GLM_10_all <- cross_validation(nfold=10, alg="GLM")

})

```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code.

## Results

These are our results:

### Cross validation
```{r results5, echo=FALSE}
# pull means from each cross validation
cv_table <- data.frame(
  GLM = c(GLM_5_all$mean, GLM_10_all$mean),
  kNNC = c(kNNC_5_all$mean, kNNC_10_all$mean)
)

# name rows in table
rownames(cv_table) <- c("**5-fold**", "**10-fold**")

# display 2x2 table
kable(cv_table, digits = 4)
```


## Discussion

The 10-fold cross validation produced a higher estimated prediction accuracy than the 5-fold cross validation for both the GLM and kNNC functions.

Based on the estimates produced above the 10-fold cross validation is suggested to make slightly better predictions.

# Part 2

Change eval=TRUE when ready to include Project1fs.R

```{r part2, eval = TRUE, code=readLines("Project1fs.R"), echo=FALSE}
```
